{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55faTi7kBglC"
      },
      "source": [
        "# üõãÔ∏è Furniture Detection with YOLOv8\n",
        "\n",
        "## 1. Environment Setup & Installation\n",
        "**Goal:** Prepare the computer (Google Colab) to run the code.\n",
        "\n",
        "We need to install specific software libraries:\n",
        "* **`ultralytics`**: The main library for YOLOv8 (the AI model we are using).\n",
        "* **`awscli`**: A tool to download images directly from the OpenImages database (hosted on Amazon AWS).\n",
        "* **`urllib3`**: A helper library for internet connections (we downgrade it to avoid version conflicts).\n",
        "\n",
        "> **Note:** We verify the installation at the end to make sure the GPU (Graphics Card) is active, which makes training much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRcRUpTZUq35"
      },
      "outputs": [],
      "source": [
        "# --- 1. Install Helper Libraries ---\n",
        "# We use '%%capture' to hide the long installation logs and keep the notebook clean.\n",
        "%%capture\n",
        "!pip install cython pyyaml requests ultralytics\n",
        "\n",
        "# --- 2. AWS CLI & Connection Fixes ---\n",
        "# OpenImages dataset is hosted on AWS. We need the AWS Command Line Interface (CLI) to download it.\n",
        "# Sometimes Colab has conflicting versions, so we clean up and reinstall.\n",
        "!pip uninstall -y awscli botocore urllib3\n",
        "!sudo apt-get remove -y awscli\n",
        "!pip install --upgrade 'urllib3<2'  # Fix for a common connection error\n",
        "!pip install awscli\n",
        "\n",
        "# --- 3. Verify Installation ---\n",
        "import torch\n",
        "print(\"Setup Complete.\")\n",
        "print(f\"CUDA (GPU) available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: You are running on CPU. Go to Runtime > Change runtime type > Hardware accelerator > T4 GPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6jUwRvVBjlV"
      },
      "source": [
        "## 2. Mount Drive & Configuration\n",
        "**Goal:** Connect Google Drive to save our data and model permanently.\n",
        "\n",
        "Since Google Colab deletes files after the session ends, we save everything to Google Drive.\n",
        "\n",
        "We also define **Constants**:  \n",
        "- **`TARGET_CLASSES_LIST`**: The specific furniture items we want to detect.  \n",
        "- **`DIRS`**: A dictionary that stores where images, labels, and CSV files are located.\n",
        "\n",
        "### üìÅ Required Folder Structure (Tree)\n",
        "\n",
        "Your Google Drive should contain the following directory tree:\n",
        "\n",
        "MyDrive/\n",
        "\n",
        "    ‚îî‚îÄ‚îÄ furniture-recommender/\n",
        "        ‚îî‚îÄ‚îÄ yolo-train/\n",
        "            ‚îú‚îÄ‚îÄ class-descriptions-boxable.csv\n",
        "            ‚îú‚îÄ‚îÄ train-annotations-bbox.csv\n",
        "            ‚îú‚îÄ‚îÄ test-annotations-bbox.csv\n",
        "\n",
        "After running the setup, the images and lables will downloaded properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR_LdBSOnmrI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import multiprocessing\n",
        "import random\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Define the main working directory in Google Drive\n",
        "BASE_DIR = \"/content/drive/MyDrive/furniture-recommender/yolo-train\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "os.chdir(BASE_DIR)\n",
        "\n",
        "# The specific objects we want the AI to learn\n",
        "TARGET_CLASSES_LIST = ['Bed', 'Cabinetry', 'Chair', 'Couch', 'Lamp', 'Table']\n",
        "\n",
        "# Define file paths for organization\n",
        "# YOLO requires a specific structure: images/ and labels/ folders.\n",
        "DIRS = {\n",
        "    \"train\": {\n",
        "        \"root\": os.path.join(BASE_DIR, \"train\"),\n",
        "        \"images\": os.path.join(BASE_DIR, \"train\", \"images\"),\n",
        "        \"labels\": os.path.join(BASE_DIR, \"train\", \"labels\"),\n",
        "        \"csv\": os.path.join(BASE_DIR, \"train-annotations-bbox.csv\") # Requires OpenImages csv\n",
        "    },\n",
        "    \"test\": {\n",
        "        \"root\": os.path.join(BASE_DIR, \"test\"),\n",
        "        \"images\": os.path.join(BASE_DIR, \"test\", \"images\"),\n",
        "        \"labels\": os.path.join(BASE_DIR, \"test\", \"labels\"),\n",
        "        \"csv\": os.path.join(BASE_DIR, \"test-annotations-bbox.csv\") # Requires OpenImages csv\n",
        "    }\n",
        "}\n",
        "\n",
        "# Path to the file that translates Class IDs (e.g., \"/m/01xy\") to Names (e.g., \"Bed\")\n",
        "CLASS_DESC_FILE = os.path.join(BASE_DIR, \"class-descriptions-boxable.csv\")\n",
        "\n",
        "# Create the necessary directories automatically\n",
        "for split in DIRS:\n",
        "    os.makedirs(DIRS[split][\"images\"], exist_ok=True)\n",
        "    os.makedirs(DIRS[split][\"labels\"], exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Configuration loaded. Working directory: {BASE_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nfebk_MBmQk"
      },
      "source": [
        "## 3. Data Download & Label Preparation\n",
        "**Goal:** Build the dataset.\n",
        "\n",
        "This step is the most complex part of the preparation. It does two things:\n",
        "1.  **Download Images:** It looks at the CSV files from OpenImages, finds images that contain our target furniture (Bed, Chair, etc.), and downloads them from AWS.\n",
        "2.  **Convert Labels:** OpenImages uses a different format for coordinates than YOLO.\n",
        "    * *OpenImages:* `XMin, XMax, YMin, YMax`\n",
        "    * *YOLO:* `Center_X, Center_Y, Width, Height` (normalized between 0 and 1).\n",
        "\n",
        "**Optimization:** We use `ThreadPoolExecutor` to download multiple images at once, making it much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjW9P6Kqk5IU"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from tqdm.auto import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# --- Helper: Map Class Names to IDs ---\n",
        "def get_class_id_map(class_desc_file):\n",
        "    \"\"\"\n",
        "    Reads the CSV file that links computer codes (e.g., /m/03ssj5) to human names (e.g., Bed).\n",
        "    Returns a dictionary: {'Bed': '/m/03ssj5', ...}\n",
        "    \"\"\"\n",
        "    if not os.path.exists(class_desc_file):\n",
        "        raise FileNotFoundError(f\"CRITICAL: Class description file missing at {class_desc_file}\")\n",
        "\n",
        "    print(\"Loading class descriptions...\")\n",
        "    df_desc = pd.read_csv(class_desc_file, header=None, names=['ClassId', 'LabelName'])\n",
        "    df_desc['LabelName'] = df_desc['LabelName'].str.replace('_', ' ') # Fix names like 'Office_Chair' -> 'Office Chair'\n",
        "    return df_desc.set_index('LabelName')['ClassId'].to_dict()\n",
        "\n",
        "# --- Helper: Download Single Image ---\n",
        "def download_image(aws_cmd):\n",
        "    \"\"\"Runs the terminal command to download a file from AWS S3.\"\"\"\n",
        "    os.system(aws_cmd)\n",
        "\n",
        "# --- Step 1: Download Images ---\n",
        "def download_dataset(dataset_type, classes, max_images_per_class=1200):\n",
        "    \"\"\"\n",
        "    Downloads images for the requested classes.\n",
        "    args:\n",
        "        dataset_type: 'train' or 'test'\n",
        "        classes: List of furniture names\n",
        "        max_images_per_class: Limit to avoid downloading too much data\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- ‚¨áÔ∏è Starting download for: {dataset_type} ---\")\n",
        "\n",
        "    images_dir = DIRS[dataset_type]['images']\n",
        "    annotation_file = DIRS[dataset_type]['csv']\n",
        "\n",
        "    if not os.path.exists(annotation_file):\n",
        "        print(f\"‚ö†Ô∏è Skipping {dataset_type}: Annotation CSV not found at {annotation_file}\")\n",
        "        return\n",
        "\n",
        "    # 1. Get Class IDs (e.g., Bed -> /m/03ssj5)\n",
        "    class_name_to_id = get_class_id_map(CLASS_DESC_FILE)\n",
        "\n",
        "    # 2. Load Annotations CSV\n",
        "    print(f\"Loading annotations from {os.path.basename(annotation_file)}...\")\n",
        "    # We only read ImageID and LabelName to save memory\n",
        "    df_ann = pd.read_csv(annotation_file, usecols=['ImageID', 'LabelName'])\n",
        "\n",
        "    commands = []\n",
        "\n",
        "    # 3. Filter images for each class\n",
        "    for class_name in classes:\n",
        "        # Ensure format matches CSV (remove underscores)\n",
        "        normalized_name = class_name.replace(\"_\", \" \")\n",
        "        class_id = class_name_to_id.get(normalized_name)\n",
        "\n",
        "        if not class_id:\n",
        "            print(f\"  ‚ö†Ô∏è Class '{class_name}' not found in OpenImages data.\")\n",
        "            continue\n",
        "\n",
        "        # Filter rows matching this class\n",
        "        df_class = df_ann[df_ann['LabelName'] == class_id]\n",
        "        image_ids = df_class['ImageID'].tolist()\n",
        "\n",
        "        # Randomly sample if we have too many images\n",
        "        if len(image_ids) > max_images_per_class:\n",
        "            image_ids = random.sample(image_ids, max_images_per_class)\n",
        "\n",
        "        print(f\"  > {class_name}: Found {len(image_ids)} images.\")\n",
        "\n",
        "        # Prepare download commands\n",
        "        for image_id in image_ids:\n",
        "            target_path = os.path.join(images_dir, f\"{image_id}.jpg\")\n",
        "            # Only download if we don't have it yet\n",
        "            if not os.path.exists(target_path):\n",
        "                # AWS S3 command for OpenImages (no sign request needed = public)\n",
        "                cmd = f'aws s3 --no-sign-request --only-show-errors cp s3://open-images-dataset/{dataset_type}/{image_id}.jpg {target_path}'\n",
        "                commands.append(cmd)\n",
        "\n",
        "    # 4. Execute Downloads (Multi-threaded)\n",
        "    # Remove duplicates (an image might have both a Bed and a Lamp)\n",
        "    commands = list(set(commands))\n",
        "    print(f\"  > Downloading {len(commands)} new images...\")\n",
        "\n",
        "    if commands:\n",
        "        # Use 4x CPU count for threads (IO bound operation)\n",
        "        workers = multiprocessing.cpu_count() * 4\n",
        "        with ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "            list(tqdm(executor.map(download_image, commands), total=len(commands)))\n",
        "    else:\n",
        "        print(\"  > All images already downloaded.\")\n",
        "\n",
        "# --- Step 2: Create YOLO Labels ---\n",
        "def prepare_yolo_labels(split_name):\n",
        "    \"\"\"\n",
        "    Converts OpenImages CSV data into YOLO .txt files.\n",
        "    YOLO format: class_id center_x center_y width height\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- üè∑Ô∏è Generating Labels for: {split_name} ---\")\n",
        "    annotations_path = DIRS[split_name]['csv']\n",
        "    output_dir = DIRS[split_name]['labels']\n",
        "\n",
        "    if not os.path.exists(annotations_path):\n",
        "        return\n",
        "\n",
        "    # 1. Load Class Names mapping\n",
        "    names_df = pd.read_csv(CLASS_DESC_FILE, header=None, names=['LabelName', 'HumanName'])\n",
        "\n",
        "    # 2. Load Annotations (Bounding Boxes)\n",
        "    df = pd.read_csv(annotations_path)\n",
        "\n",
        "    # 3. Merge to get readable names (e.g., 'Bed' instead of '/m/03ssj5')\n",
        "    df = df.merge(names_df, on='LabelName', how='left')\n",
        "\n",
        "    # Filter only our target furniture classes\n",
        "    df = df[df['HumanName'].isin(TARGET_CLASSES_LIST)]\n",
        "\n",
        "    # 4. Map names to YOLO IDs (0, 1, 2, 3...)\n",
        "    # It's crucial to sort the list so ID 0 is always the same class\n",
        "    TARGET_CLASSES_LIST.sort()\n",
        "    class_map = {name: idx for idx, name in enumerate(TARGET_CLASSES_LIST)}\n",
        "    print(f\"  > Class Map: {class_map}\")\n",
        "\n",
        "    # 5. Calculate YOLO Coordinates\n",
        "    # OpenImages gives min/max. YOLO needs center + width/height relative to image size (0-1).\n",
        "    df['width'] = df['XMax'] - df['XMin']\n",
        "    df['height'] = df['YMax'] - df['YMin']\n",
        "    df['x_center'] = df['XMin'] + (df['width'] / 2)\n",
        "    df['y_center'] = df['YMin'] + (df['height'] / 2)\n",
        "    df['class_id'] = df['HumanName'].map(class_map)\n",
        "\n",
        "    # 6. Save .txt files\n",
        "    # Group data by image so we write one file per image\n",
        "    grouped = df.groupby('ImageID')\n",
        "\n",
        "    count = 0\n",
        "    for image_id, group in tqdm(grouped, desc=\"Writing .txt files\"):\n",
        "        img_path = os.path.join(DIRS[split_name]['images'], f\"{image_id}.jpg\")\n",
        "\n",
        "        # Only create a label file if the image actually exists (was downloaded)\n",
        "        if os.path.exists(img_path):\n",
        "            txt_filename = os.path.join(output_dir, f\"{image_id}.txt\")\n",
        "            with open(txt_filename, 'w') as f:\n",
        "                for _, row in group.iterrows():\n",
        "                    # Write line: class_id x y w h\n",
        "                    line = f\"{int(row['class_id'])} {row['x_center']:.6f} {row['y_center']:.6f} {row['width']:.6f} {row['height']:.6f}\\n\"\n",
        "                    f.write(line)\n",
        "            count += 1\n",
        "    print(f\"  > Created {count} label files.\")\n",
        "\n",
        "# --- EXECUTE PIPELINE ---\n",
        "# 1. Download Train Data\n",
        "download_dataset(\"train\", TARGET_CLASSES_LIST)\n",
        "prepare_yolo_labels(\"train\")\n",
        "\n",
        "# 2. Download Test Data\n",
        "download_dataset(\"test\", TARGET_CLASSES_LIST)\n",
        "prepare_yolo_labels(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT6c4p7Xvp40"
      },
      "source": [
        "## 4. Create Dataset Config (data.yaml)\n",
        "**Goal:** Tell YOLO where the data is.\n",
        "\n",
        "YOLO training requires a `.yaml` file that specifies:\n",
        "1.  Path to **Train** images.\n",
        "2.  Path to **Validation/Test** images.\n",
        "3.  Number of classes (`nc`).\n",
        "4.  List of class names (`names`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94EV61Eqt8qa"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Ensure the list is sorted same as in label generation\n",
        "TARGET_CLASSES_LIST.sort()\n",
        "\n",
        "yaml_content = {\n",
        "    'train': DIRS['train']['images'],\n",
        "    'val': DIRS['test']['images'], # We use test set for validation here\n",
        "    'nc': len(TARGET_CLASSES_LIST),\n",
        "    'names': TARGET_CLASSES_LIST\n",
        "}\n",
        "\n",
        "yaml_path = os.path.join(BASE_DIR, 'data.yaml')\n",
        "\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(yaml_content, f, default_flow_style=None)\n",
        "\n",
        "print(f\"‚úÖ data.yaml created at: {yaml_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6sOI9mAvvZ3"
      },
      "source": [
        "## 5. Train YOLOv8 Model (Auto-Resume Support)\n",
        "**Goal:** Teach the AI to recognize furniture.\n",
        "\n",
        "We load the base model (`yolov8n.pt` - \"Nano\", the fastest and smallest version).\n",
        "Then we start training for 200 epochs (cycles).\n",
        "\n",
        "**Auto-Resume Logic:**\n",
        "Training can take hours. If Google Colab disconnects, we don't want to start from zero.\n",
        "The code below checks if a previous training run exists.\n",
        "* If `last.pt` exists: It loads it and sets `resume=True`.\n",
        "* If not: It starts a fresh training session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1RtFm8st8qa"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Project Name (Folder name where results are saved)\n",
        "PROJECT_NAME = 'furniture_detector_model'\n",
        "RUNS_DIR = os.path.join(BASE_DIR, 'runs', 'detect')\n",
        "LAST_CHECKPOINT = os.path.join(RUNS_DIR, PROJECT_NAME, 'weights', 'last.pt')\n",
        "\n",
        "print(f\"Checking for existing checkpoint at: {LAST_CHECKPOINT}\")\n",
        "\n",
        "if os.path.exists(LAST_CHECKPOINT):\n",
        "    print(\"üîÑ Found incomplete training. Resuming from last checkpoint...\")\n",
        "    # Load the partially trained model\n",
        "    model = YOLO(LAST_CHECKPOINT)\n",
        "    resume_training = True\n",
        "else:\n",
        "    print(\"‚ú® No previous checkpoint found. Starting fresh training...\")\n",
        "    # Load a pre-trained generic model (Transfer Learning)\n",
        "    model = YOLO('yolov8n.pt')\n",
        "    resume_training = False\n",
        "\n",
        "# Start Training\n",
        "# If resuming, we don't need to specify args again, YOLO reads them from the file.\n",
        "if resume_training:\n",
        "    results = model.train(resume=True)\n",
        "else:\n",
        "    results = model.train(\n",
        "        data=os.path.join(BASE_DIR, 'data.yaml'),\n",
        "        epochs=200,          # How many times to go over the data\n",
        "        imgsz=640,           # Image resolution\n",
        "        batch=32,            # How many images to process at once\n",
        "        device=0,            # Use GPU (0)\n",
        "        project=os.path.join(BASE_DIR, 'runs/detect'),\n",
        "        name=PROJECT_NAME,\n",
        "        exist_ok=True,       # Allow overwriting folder if not resuming\n",
        "        patience=50          # Stop early if no improvement for 50 epochs\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Training Complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbEkfM9cBmVP"
      },
      "source": [
        "## 6. Test on Random Image\n",
        "**Goal:** See the results with our own eyes.\n",
        "\n",
        "We pick a random image from the test set, run the trained model, and visualize the detected boxes.\n",
        "We also perform cleanup to avoid filling the Google Drive with temporary crop files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db6f45cc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "# Path to the best model saved during training\n",
        "best_model_path = os.path.join(RUNS_DIR, PROJECT_NAME, 'weights', 'best.pt')\n",
        "inference_output = os.path.join(BASE_DIR, 'inference_results')\n",
        "\n",
        "if not os.path.exists(best_model_path):\n",
        "    print(f\"‚ùå Error: Model not found at {best_model_path}. Did training finish?\")\n",
        "else:\n",
        "    # Load the trained model\n",
        "    model = YOLO(best_model_path)\n",
        "\n",
        "    # Find test images\n",
        "    test_images_dir = DIRS['test']['images']\n",
        "    all_test_images = glob(os.path.join(test_images_dir, \"*.jpg\"))\n",
        "\n",
        "    if not all_test_images:\n",
        "        print(\"No images found in test directory.\")\n",
        "    else:\n",
        "        # Pick one random image\n",
        "        random_image = random.choice(all_test_images)\n",
        "        print(f\"Testing on image: {os.path.basename(random_image)}\")\n",
        "\n",
        "        # Run Inference (Prediction)\n",
        "        # save_crop=True creates small images of detected objects\n",
        "        results = model.predict(\n",
        "            source=random_image,\n",
        "            save=True,\n",
        "            save_crop=True,\n",
        "            project=inference_output,\n",
        "            name='prediction',\n",
        "            exist_ok=True, # Overwrite previous prediction folder\n",
        "            conf=0.25      # Minimum confidence (25%) to show a box\n",
        "        )\n",
        "\n",
        "        # --- Visualization ---\n",
        "        # Plot the main image with boxes\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        # results[0].plot() returns a BGR array, convert to RGB for Matplotlib\n",
        "        res_plotted = results[0].plot()\n",
        "        plt.imshow(cv2.cvtColor(res_plotted, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Detections: {os.path.basename(random_image)}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # --- Clean Up ---\n",
        "        # We delete the 'inference_results' folder to keep Drive clean\n",
        "        if os.path.exists(inference_output):\n",
        "             shutil.rmtree(inference_output)\n",
        "             print(f\"üßπ Cleanup: Deleted temporary folder {inference_output}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
